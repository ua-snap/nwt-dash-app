{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "507298e8",
   "metadata": {},
   "source": [
    "# Repairing geographic locations, place names, and extracted data for the NWT Climate Explorer.\n",
    "\n",
    "## Issue\n",
    "The location of Inuvik, NWT was found to be incorrect by about ten degrees of longitude. A closer examination of all point locations used by the web tool found that many of the geographic coordinates were in need of refinement and that some place names needed to be updated.\n",
    "\n",
    "## Fix\n",
    "A revised spreadsheet of NWT geographic locations was produced (see https://github.com/ua-snap/geospatial-vector-veracity/blob/main/vector_data/point/nwt_point_locations.csv) and used to re-extract downscaled data for each location.\n",
    "\n",
    "## Validation\n",
    "This notebook will compare the existing data to the newly extracted data and check for data model integrity and for qualitative similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087e094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5f804",
   "metadata": {},
   "source": [
    "The previously extracted CSV files (incorrect for Inuvik) are still on branch `master` while the freshly extracted data is on branch `inuvik-rextraction` (forgive the missing 'e'). I want to pull both sets of CSV files and compare them. I'll use the `subprocess` module to checkout the different git branches. This is probably not advisable and should only be used if both branches have clean working trees (no changes, nothing staged, etc.). Using git in the notebook is confusing (but fun!) because it is sensitive to the state of the git repository as it was left in the terminal. Only two branches are relevant here so I can be agnostic regarding which branch this \"starts\" on. This technique will also hang up if this notebook is being tracked in git because it will see the modifications and yell at you about performing a `checkout`. The recommendation is to tell git to ignore notebooks while working here, and then re-track notebooks when you are done / ready to commit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26025725",
   "metadata": {},
   "outputs": [],
   "source": [
    "di_branches = defaultdict()\n",
    "di_branches['master'] = 'inuvik-rextraction'\n",
    "di_branches['inuvik-rextraction'] = 'master'\n",
    "\n",
    "def which_branch():\n",
    "    proc_branch = subprocess.Popen([\"git\", \"branch\"], stdout=subprocess.PIPE, universal_newlines=True)\n",
    "    out_branch = proc_branch.communicate()[0].splitlines()\n",
    "    current_branch = [x for x in out_branch if x[0] == '*'][0].split(' ')[-1]\n",
    "    return current_branch\n",
    "\n",
    "def switch_branch(di_branches):\n",
    "    checkout = subprocess.Popen([\"git\", \"checkout\", di_branches[which_branch()]],\n",
    "                                stdout=subprocess.PIPE,\n",
    "                                universal_newlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19ac2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inuvik-rextraction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_branch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3f8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = ['historical', 'rcp45', 'rcp60', 'rcp85']\n",
    "\n",
    "di_csv = defaultdict()\n",
    "\n",
    "def qa_prep():\n",
    "    di_csv[which_branch()] = {}\n",
    "    for sc in scenarios:\n",
    "        di_csv[which_branch()][sc] = {}\n",
    "        df = pd.read_csv(glob('../data/*' + sc + '*.csv')[0])\n",
    "        di_csv[which_branch()][sc]['csv'] = df\n",
    "        di_csv[which_branch()][sc]['shape'] = df.shape\n",
    "        di_csv[which_branch()][sc]['models'] = sorted(list(df.model.unique()))\n",
    "        di_csv[which_branch()][sc]['years'] = sorted(list(df.model.unique()))\n",
    "        di_csv[which_branch()][sc]['place_names'] = sorted(list(df.community.unique()))\n",
    "\n",
    "qa_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd41b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_branch(di_branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a52d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inuvik-rextraction'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_branch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c180dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60e4c39",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'master'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e8d6780ff05d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Expectation: models and time spans (years) did not change across extractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscenarios\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdi_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'master'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdi_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inuvik-rextraction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0myr_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdi_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'master'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'years'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdi_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inuvik-rextraction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'years'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myr_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'master'"
     ]
    }
   ],
   "source": [
    "# Expectation: models and time spans (years) did not change across extractions\n",
    "for sc in scenarios:\n",
    "    model_check = di_csv['master'][sc]['models'] == di_csv['inuvik-rextraction'][sc]['models']  \n",
    "    yr_check = di_csv['master'][sc]['years'] == di_csv['inuvik-rextraction'][sc]['years']\n",
    "    print(sc, model_check, yr_check)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a29f04a",
   "metadata": {},
   "source": [
    "However, changes to the place names were made, and the number of communities was reduced by one in freshly extracted data. Bechoko was formerly represented by separate extractions for Rae and Edzo, two former communities that are are only a few miles apart. They are now together...see encyclopedia article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sc in scenarios:\n",
    "    print(sc)\n",
    "    old_places = di_csv['master'][sc]['place_names']\n",
    "    new_places = di_csv['fix-point-locations-and-names'][sc]['place_names']\n",
    "    old_locs_not_in_new = list(set(old_places) - set(new_places))\n",
    "    new_locs_not_in_old = list(set(new_places) - set(old_places))\n",
    "    print(sorted(old_locs_not_in_new))\n",
    "    print(sorted(new_locs_not_in_old))\n",
    "    print(\"Old places: %d\" % len(old_places))\n",
    "    print(\"New places: %d\" % len(new_places))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bf1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK so we reduced the number of communities by one\n",
    "# so the shape of the newly extracted dataframes has changed\n",
    "# how many rows per community for each scenario?\n",
    "# That should be the difference in dataframe shapes\n",
    "for sc in scenarios:\n",
    "    print(sc)\n",
    "    old_shape = di_csv['master'][sc]['shape']\n",
    "    new_shape = di_csv['fix-point-locations-and-names'][sc]['shape']\n",
    "    row_delta = old_shape[0] - new_shape[0]\n",
    "    print(\"Old CSV Shape:\", old_shape)\n",
    "    print(\"New CSV Shape:\", new_shape)\n",
    "    print(\"Old - New Shape Difference (Number Rows):\", row_delta)\n",
    "    rows_per_location = di_csv['master'][sc]['csv'].query(\"community == 'Inuvik'\").shape[0]\n",
    "    print(\"Shape Difference Accounted for by reduction of point locations by one:\", row_delta == rows_per_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9379e7",
   "metadata": {},
   "source": [
    "I am satisfied that the data is essentially intact between the two extractions. The same time ranges, models, and scenarios are all accounted for. Now I'll do a brief qualitative examination to look at a few changes in the actual data itself - and I will certainly look at Inuvik because it was known to be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "old_inuvik = di_csv['master']['rcp85']['csv'].query(\"model == '5ModelAvg' and community == 'Inuvik'\")\n",
    "new_inuvik = di_csv['fix-point-locations-and-names']['rcp85']['csv'].query(\"model == '5ModelAvg' and name == 'Inuvik'\")\n",
    "\n",
    "plt.plot(new_inuvik[['year', 'tas']].groupby('year').mean(), label='NEW')\n",
    "plt.plot(old_inuvik[['year', 'tas']].groupby('year').mean(), label='OLD')    \n",
    "plt.legend()\n",
    "plt.title('Inuvik')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('temp (RCP 8.5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "old_inuvik = di_csv['master']['rcp60']['csv'].query(\"model == '5ModelAvg' and community == 'Inuvik'\")\n",
    "new_inuvik = di_csv['fix-point-locations-and-names']['rcp60']['csv'].query(\"model == '5ModelAvg' and name == 'Inuvik'\")\n",
    "\n",
    "plt.plot(new_inuvik[['year', 'pr']].groupby('year').mean(), label='NEW')\n",
    "plt.plot(old_inuvik[['year', 'pr']].groupby('year').mean(), label='OLD')    \n",
    "plt.legend()\n",
    "plt.title('Inuvik')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Precip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "old_inuvik = di_csv['master']['rcp60']['csv'].query(\"model == '5ModelAvg' and community == 'Behchoko (Edzo)'\")\n",
    "new_inuvik = di_csv['fix-point-locations-and-names']['rcp60']['csv'].query(\"model == '5ModelAvg' and name == 'Behchokǫ̀'\")\n",
    "\n",
    "plt.plot(new_inuvik[['year', 'tas']].groupby('year').mean(), label='NEW')\n",
    "plt.plot(old_inuvik[['year', 'tas']].groupby('year').mean(), label='OLD')    \n",
    "plt.legend()\n",
    "plt.title('Behchokǫ̀')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd06011",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "old_inuvik = di_csv['master']['rcp60']['csv'].query(\"model == '5ModelAvg' and community == 'Behchoko (Edzo)'\")\n",
    "new_inuvik = di_csv['fix-point-locations-and-names']['rcp60']['csv'].query(\"model == '5ModelAvg' and name == 'Behchokǫ̀'\")\n",
    "\n",
    "plt.plot(new_inuvik[['year', 'pr']].groupby('year').mean(), label='NEW')\n",
    "plt.plot(old_inuvik[['year', 'pr']].groupby('year').mean(), label='OLD')    \n",
    "plt.legend()\n",
    "plt.title('Behchokǫ̀')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ef937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
